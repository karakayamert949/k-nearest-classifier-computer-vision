{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation and loading\n",
    "# get data from pickle file\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, \"rb\") as fo:\n",
    "        dict = pickle.load(fo, encoding=\"bytes\")\n",
    "    return dict\n",
    "\n",
    "\n",
    "# get train data 1-6 append them to a list\n",
    "temp_xTrain = []\n",
    "temp_yTrain = []\n",
    "for i in range(1, 6):\n",
    "    data = unpickle(\n",
    "        r\"C:\\Users\\mert\\Desktop\\yazılımlar\\python\\computer vision\\cs231n\\cifar-10-batches-py\\data_batch_\"+str(i))\n",
    "    temp_xTrain.append(data[b'data'])\n",
    "    temp_yTrain.append(data[b'labels'])\n",
    "\n",
    "# make one list from the list of lists train data is now ready\n",
    "temp_xTrain = np.concatenate(temp_xTrain)\n",
    "temp_yTrain = np.concatenate(temp_yTrain)\n",
    "\n",
    "# use only first 5000 data to test\n",
    "temp_xTrain = temp_xTrain[:1000]\n",
    "temp_yTrain = temp_yTrain[:1000]\n",
    "\n",
    "tmpXtrain = []\n",
    "for id, im in enumerate(temp_xTrain):\n",
    "    # 1024 3 yer değiştirdiğinde hata verdi? çünkü 3 channel var rgb için 3 row gerekli 1024 olmaz\n",
    "    im = np.reshape(im, (3, 1024))\n",
    "    tmpXtrain.append((np.reshape(im, (3, 32, 32))).transpose(\n",
    "        1, 2, 0))  # 1. başta 2. ortada 0. en sonda\n",
    "temp_xTrain = np.array(tmpXtrain)\n",
    "\n",
    "\n",
    "tmpXtrainGray = []\n",
    "for id, im in enumerate(temp_xTrain):\n",
    "    ima = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "    tmpXtrainGray.append(ima)\n",
    "temp_xTrain = np.array(tmpXtrainGray)\n",
    "\n",
    "# data normalization #################################################\n",
    "tmpXtrainNorm=[]\n",
    "for id,im in enumerate(temp_xTrain):\n",
    "    ima=(im/255)\n",
    "    tmpXtrainNorm.append(ima)\n",
    "temp_xTrain=np.array(tmpXtrainNorm)\n",
    "\n",
    "train_len = temp_xTrain.shape[0]\n",
    "\n",
    "temp_xTrain=np.reshape(temp_xTrain,(train_len,1024))\n",
    "#############################################################################\n",
    "\n",
    "\n",
    "\n",
    "xTrain1 = temp_xTrain[:train_len//5]\n",
    "xTrain2 = temp_xTrain[train_len//5:2*train_len//5]\n",
    "xTrain3 = temp_xTrain[2*train_len//5:3*train_len//5]\n",
    "xTrain4 = temp_xTrain[3*train_len//5:4*train_len//5]\n",
    "xTrain5 = temp_xTrain[4*train_len//5:]\n",
    "xTRAINS = (xTrain1, xTrain2, xTrain3, xTrain4, xTrain5)\n",
    "\n",
    "yTrain1 = temp_yTrain[:train_len//5]\n",
    "yTrain2 = temp_yTrain[train_len//5:2*train_len//5]\n",
    "yTrain3 = temp_yTrain[2*train_len//5:3*train_len//5]\n",
    "yTrain4 = temp_yTrain[3*train_len//5:4*train_len//5]\n",
    "yTrain5 = temp_yTrain[4*train_len//5:]\n",
    "yTRAINS = (yTrain1, yTrain2, yTrain3, yTrain4, yTrain5)\n",
    "\n",
    "# get test data\n",
    "data = unpickle(\n",
    "    r\"C:\\Users\\mert\\Desktop\\yazılımlar\\python\\computer vision\\cs231n\\cifar-10-batches-py\\test_batch\")\n",
    "xTest = (data[b'data'])\n",
    "yTest = (data[b'labels'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "im = temp_xTrain[134]\n",
    "plt.imshow(im, cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighbor:\n",
    "    def train(self, XTrain, YTrain):\n",
    "        self.XTrain = XTrain\n",
    "        self.YTrain = YTrain\n",
    "\n",
    "    def predict(self, XTest, k=1):\n",
    "        num_test = XTest.shape[0]\n",
    "        YPrediction = np.zeros(num_test, dtype=self.YTrain.dtype)\n",
    "        for i in range(num_test):\n",
    "            distances = np.sum(abs(XTest[i, :] - self.XTrain), axis=1)\n",
    "            # All elements smaller than the kth element are before moved before this element(think position)\n",
    "            minDistances = np.partition(distances, k-1)[:k]\n",
    "\n",
    "            minIndices = []\n",
    "            for dist in minDistances:\n",
    "                minIndices.append(np.where(distances == dist)[0][0])\n",
    "\n",
    "            trainList = []\n",
    "            for id in minIndices:\n",
    "                trainList.append(self.YTrain[id])\n",
    "\n",
    "            YPrediction[i] = max(trainList, key=trainList.count)\n",
    "\n",
    "        return YPrediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "k_list = [1, 7,14]\n",
    "validation_accuracies = []\n",
    "nn = NearestNeighbor()\n",
    "for k in k_list:\n",
    "    for xValidation, yValidation in zip(xTRAINS, yTRAINS):\n",
    "        # use a particular value of k and evaluation on validation data\n",
    "        #otherXTrains=list(filter(lambda xtrain: xtrain==xValidation,xTRAINS))\n",
    "\n",
    "        otherXTrains = [\n",
    "            xtrain for xtrain in xTRAINS if not np.allclose(xtrain, xValidation)]\n",
    "        otherXTrains = np.concatenate(otherXTrains)\n",
    "\n",
    "        #otherYTrains=[ytrain for ytrain in yTRAINS if ytrain != yValidation]\n",
    "\n",
    "        otherYTrains = [\n",
    "            ytrain for ytrain in yTRAINS if not np.allclose(ytrain, yValidation)]\n",
    "        otherYTrains = np.concatenate(otherYTrains)\n",
    "\n",
    "        nn.train(otherXTrains, otherYTrains)\n",
    "        yPredict = nn.predict(xValidation, k)\n",
    "        acc = np.mean(yPredict == yValidation)\n",
    "        print(f'accuracy: {acc} at k={k}')\n",
    "        # keep track of what works on the validation set\n",
    "        validation_accuracies.append((k, acc))\n",
    "\n",
    "x, y = zip(*validation_accuracies)\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.plot(x, y, \"+\")\n",
    "\n",
    "acc_dict = {}\n",
    "for x, y in validation_accuracies:\n",
    "    if x not in acc_dict:\n",
    "        acc_dict[x] = [y]\n",
    "    else:\n",
    "        acc_dict[x].append(y)\n",
    "means = []\n",
    "for k in k_list:\n",
    "    means.append(np.mean(acc_dict[k]))\n",
    "\n",
    "plt.plot(k_list, means, \"ro\",)\n",
    "plt.plot(k_list, means, \"r-\", linewidth=0.5)\n",
    "plt.xlabel(\"k neighbor\", fontsize=20)\n",
    "plt.ylabel(\"accuracy\", fontsize=20)\n",
    "plt.title(\"k-nearest-neighbor\", fontsize=30)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19f8f9ebccd493d1979261b88c51ecd06bf2efdee26e5f5e5ddb3d1c8ea2e26f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
